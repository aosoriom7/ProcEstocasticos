{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "32HANrEZr_Hi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92qmgyOts9uo",
    "outputId": "b5dc923f-3eaa-4d44-a0f0-f03f738854fb"
   },
   "outputs": [],
   "source": [
    "CHD =fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "V6f6s55QsXc8",
    "outputId": "2408ab6c-d7ee-4294-e173-f1b8476e5c3b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  \n",
       "0        -122.23  \n",
       "1        -122.22  \n",
       "2        -122.24  \n",
       "3        -122.25  \n",
       "4        -122.25  \n",
       "...          ...  \n",
       "20635    -121.09  \n",
       "20636    -121.21  \n",
       "20637    -121.22  \n",
       "20638    -121.32  \n",
       "20639    -121.24  \n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=CHD.data,columns=CHD.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef9U8EK8tgpT",
    "outputId": "dc24c8d3-8657-474c-a6c8-4e72190e0b7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8) (20640,)\n"
     ]
    }
   ],
   "source": [
    "x_data = CHD.data\n",
    "y = CHD['target']\n",
    "\n",
    "print(x_data.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SLtX2s7KWRVC"
   },
   "outputs": [],
   "source": [
    "X_train, X_eval,y_train,y_eval=train_test_split(x_data,y,test_size=0.3,random_state=101)\n",
    "\n",
    "scaler_model = StandardScaler()\n",
    "X_train = scaler_model.fit_transform(X_train)\n",
    "X_eval   = scaler_model.transform(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "i8dGtWoRXJn3"
   },
   "outputs": [],
   "source": [
    "def DNN_Regressor(hidden_units,n_features):\n",
    "    Inputs = tf.keras.layers.Input(shape=n_features)\n",
    "    c = 0\n",
    "    for i in hidden_units:\n",
    "        if c==0:\n",
    "            Hidden = tf.keras.layers.Dense(i,activation='relu')(Inputs)\n",
    "        else:\n",
    "            Hidden = tf.keras.layers.Dense(i,activation='relu')(Hidden)\n",
    "        c =+1\n",
    "    Out = tf.keras.layers.Dense(1,activation='relu')(Hidden)\n",
    "\n",
    "    return tf.keras.Model(inputs=Inputs, outputs=Out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IFIAN2S3ZOQ_",
    "outputId": "229f48dc-6ede-4ea4-a63b-b55ee10614ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                70        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 197\n",
      "Trainable params: 197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Hidden units son las neuronas de las capas ocultas y se puede modificar tanto nÃºmero de neuronas como el nÃºmero de capas\n",
    "# asÃ­mismo los parÃ¡metros de la red como el optimizador y el learning rate\n",
    "model = DNN_Regressor(hidden_units=[6,10,6],n_features = X_train.shape[1])\n",
    "opt = tf.keras.optimizers.Adagrad(learning_rate=1e-1)\n",
    "model.compile(optimizer=opt,loss='mse',metrics=['mse','mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLbpojcpZ_G8",
    "outputId": "2c093477-1532-414c-8860-0b18cc2a3bd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "362/362 [==============================] - 8s 11ms/step - loss: 0.8970 - mse: 0.8970 - mae: 0.6575 - val_loss: 0.3821 - val_mse: 0.3821 - val_mae: 0.4411\n",
      "Epoch 2/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3831 - mse: 0.3831 - mae: 0.4438 - val_loss: 0.3724 - val_mse: 0.3724 - val_mae: 0.4252\n",
      "Epoch 3/100\n",
      "362/362 [==============================] - 1s 1ms/step - loss: 0.3609 - mse: 0.3609 - mae: 0.4307 - val_loss: 0.3599 - val_mse: 0.3599 - val_mae: 0.4232\n",
      "Epoch 4/100\n",
      "362/362 [==============================] - 1s 1ms/step - loss: 0.3482 - mse: 0.3482 - mae: 0.4223 - val_loss: 0.3409 - val_mse: 0.3409 - val_mae: 0.4244\n",
      "Epoch 5/100\n",
      "362/362 [==============================] - 1s 1ms/step - loss: 0.3400 - mse: 0.3400 - mae: 0.4201 - val_loss: 0.3414 - val_mse: 0.3414 - val_mae: 0.4190\n",
      "Epoch 6/100\n",
      "362/362 [==============================] - 1s 1ms/step - loss: 0.3518 - mse: 0.3518 - mae: 0.4220 - val_loss: 0.3505 - val_mse: 0.3505 - val_mae: 0.4300\n",
      "Epoch 7/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3457 - mse: 0.3457 - mae: 0.4199 - val_loss: 0.3457 - val_mse: 0.3457 - val_mae: 0.4229\n",
      "Epoch 8/100\n",
      "362/362 [==============================] - 1s 1ms/step - loss: 0.3290 - mse: 0.3290 - mae: 0.4081 - val_loss: 0.3379 - val_mse: 0.3379 - val_mae: 0.4171\n",
      "Epoch 9/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3307 - mse: 0.3307 - mae: 0.4076 - val_loss: 0.3368 - val_mse: 0.3368 - val_mae: 0.4086\n",
      "Epoch 10/100\n",
      "362/362 [==============================] - 1s 1ms/step - loss: 0.3315 - mse: 0.3315 - mae: 0.4105 - val_loss: 0.3313 - val_mse: 0.3313 - val_mae: 0.4094\n",
      "Epoch 11/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3274 - mse: 0.3274 - mae: 0.4068 - val_loss: 0.3444 - val_mse: 0.3444 - val_mae: 0.4234\n",
      "Epoch 12/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3495 - mse: 0.3495 - mae: 0.4156 - val_loss: 0.3330 - val_mse: 0.3330 - val_mae: 0.4099\n",
      "Epoch 13/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3309 - mse: 0.3309 - mae: 0.4040 - val_loss: 0.3370 - val_mse: 0.3370 - val_mae: 0.4078\n",
      "Epoch 14/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3428 - mse: 0.3428 - mae: 0.4146 - val_loss: 0.3311 - val_mse: 0.3311 - val_mae: 0.4137\n",
      "Epoch 15/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3225 - mse: 0.3225 - mae: 0.4071 - val_loss: 0.3293 - val_mse: 0.3293 - val_mae: 0.4056\n",
      "Epoch 16/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3368 - mse: 0.3368 - mae: 0.4101 - val_loss: 0.3371 - val_mse: 0.3371 - val_mae: 0.4055\n",
      "Epoch 17/100\n",
      "362/362 [==============================] - 0s 918us/step - loss: 0.3497 - mse: 0.3497 - mae: 0.4147 - val_loss: 0.3329 - val_mse: 0.3329 - val_mae: 0.4147\n",
      "Epoch 18/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3321 - mse: 0.3321 - mae: 0.4100 - val_loss: 0.3297 - val_mse: 0.3297 - val_mae: 0.4092\n",
      "Epoch 19/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3364 - mse: 0.3364 - mae: 0.4061 - val_loss: 0.3279 - val_mse: 0.3279 - val_mae: 0.4052\n",
      "Epoch 20/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3354 - mse: 0.3354 - mae: 0.4108 - val_loss: 0.3365 - val_mse: 0.3365 - val_mae: 0.4053\n",
      "Epoch 21/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3269 - mse: 0.3269 - mae: 0.4052 - val_loss: 0.3288 - val_mse: 0.3288 - val_mae: 0.4092\n",
      "Epoch 22/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3287 - mse: 0.3287 - mae: 0.4074 - val_loss: 0.3314 - val_mse: 0.3314 - val_mae: 0.4130\n",
      "Epoch 23/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3382 - mse: 0.3382 - mae: 0.4111 - val_loss: 0.3302 - val_mse: 0.3302 - val_mae: 0.4077\n",
      "Epoch 24/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3380 - mse: 0.3380 - mae: 0.4093 - val_loss: 0.3280 - val_mse: 0.3280 - val_mae: 0.4030\n",
      "Epoch 25/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3175 - mse: 0.3175 - mae: 0.4003 - val_loss: 0.3307 - val_mse: 0.3307 - val_mae: 0.4086\n",
      "Epoch 26/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3321 - mse: 0.3321 - mae: 0.4069 - val_loss: 0.3267 - val_mse: 0.3267 - val_mae: 0.4044\n",
      "Epoch 27/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3182 - mse: 0.3182 - mae: 0.4003 - val_loss: 0.3276 - val_mse: 0.3276 - val_mae: 0.4027\n",
      "Epoch 28/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3181 - mse: 0.3181 - mae: 0.3993 - val_loss: 0.3317 - val_mse: 0.3317 - val_mae: 0.4116\n",
      "Epoch 29/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3073 - mse: 0.3073 - mae: 0.3950 - val_loss: 0.3299 - val_mse: 0.3299 - val_mae: 0.4033\n",
      "Epoch 30/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3257 - mse: 0.3257 - mae: 0.4046 - val_loss: 0.3265 - val_mse: 0.3265 - val_mae: 0.4040\n",
      "Epoch 31/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3243 - mse: 0.3243 - mae: 0.4032 - val_loss: 0.3277 - val_mse: 0.3277 - val_mae: 0.4077\n",
      "Epoch 32/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3191 - mse: 0.3191 - mae: 0.3986 - val_loss: 0.3266 - val_mse: 0.3266 - val_mae: 0.4023\n",
      "Epoch 33/100\n",
      "362/362 [==============================] - 1s 1ms/step - loss: 0.3265 - mse: 0.3265 - mae: 0.4002 - val_loss: 0.3264 - val_mse: 0.3264 - val_mae: 0.4039\n",
      "Epoch 34/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3233 - mse: 0.3233 - mae: 0.4028 - val_loss: 0.3257 - val_mse: 0.3257 - val_mae: 0.4020\n",
      "Epoch 35/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3181 - mse: 0.3181 - mae: 0.4003 - val_loss: 0.3272 - val_mse: 0.3272 - val_mae: 0.4022\n",
      "Epoch 36/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3265 - mse: 0.3265 - mae: 0.4014 - val_loss: 0.3255 - val_mse: 0.3255 - val_mae: 0.3989\n",
      "Epoch 37/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3205 - mse: 0.3205 - mae: 0.3996 - val_loss: 0.3253 - val_mse: 0.3253 - val_mae: 0.4002\n",
      "Epoch 38/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3302 - mse: 0.3302 - mae: 0.4045 - val_loss: 0.3258 - val_mse: 0.3258 - val_mae: 0.4049\n",
      "Epoch 39/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3149 - mse: 0.3149 - mae: 0.3990 - val_loss: 0.3362 - val_mse: 0.3362 - val_mae: 0.4181\n",
      "Epoch 40/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3196 - mse: 0.3196 - mae: 0.4011 - val_loss: 0.3255 - val_mse: 0.3255 - val_mae: 0.3979\n",
      "Epoch 41/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3238 - mse: 0.3238 - mae: 0.4003 - val_loss: 0.3241 - val_mse: 0.3241 - val_mae: 0.4005\n",
      "Epoch 42/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3136 - mse: 0.3136 - mae: 0.3966 - val_loss: 0.3242 - val_mse: 0.3242 - val_mae: 0.3981\n",
      "Epoch 43/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3119 - mse: 0.3119 - mae: 0.3927 - val_loss: 0.3242 - val_mse: 0.3242 - val_mae: 0.4038\n",
      "Epoch 44/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3125 - mse: 0.3125 - mae: 0.3978 - val_loss: 0.3232 - val_mse: 0.3232 - val_mae: 0.4005\n",
      "Epoch 45/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3217 - mse: 0.3217 - mae: 0.4020 - val_loss: 0.3225 - val_mse: 0.3225 - val_mae: 0.3978\n",
      "Epoch 46/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3241 - mse: 0.3241 - mae: 0.3977 - val_loss: 0.3283 - val_mse: 0.3283 - val_mae: 0.4097\n",
      "Epoch 47/100\n",
      "362/362 [==============================] - 1s 1ms/step - loss: 0.3216 - mse: 0.3216 - mae: 0.4015 - val_loss: 0.3274 - val_mse: 0.3274 - val_mae: 0.4009\n",
      "Epoch 48/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3186 - mse: 0.3186 - mae: 0.3975 - val_loss: 0.3210 - val_mse: 0.3210 - val_mae: 0.3980\n",
      "Epoch 49/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3169 - mse: 0.3169 - mae: 0.3987 - val_loss: 0.3203 - val_mse: 0.3203 - val_mae: 0.4024\n",
      "Epoch 50/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3341 - mse: 0.3341 - mae: 0.4074 - val_loss: 0.3235 - val_mse: 0.3235 - val_mae: 0.4049\n",
      "Epoch 51/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3268 - mse: 0.3268 - mae: 0.4018 - val_loss: 0.3199 - val_mse: 0.3199 - val_mae: 0.4011\n",
      "Epoch 52/100\n",
      "362/362 [==============================] - 1s 1ms/step - loss: 0.3043 - mse: 0.3043 - mae: 0.3945 - val_loss: 0.3239 - val_mse: 0.3239 - val_mae: 0.3958\n",
      "Epoch 53/100\n",
      "362/362 [==============================] - 1s 1ms/step - loss: 0.3137 - mse: 0.3137 - mae: 0.3957 - val_loss: 0.3192 - val_mse: 0.3192 - val_mae: 0.3961\n",
      "Epoch 54/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3179 - mse: 0.3179 - mae: 0.3968 - val_loss: 0.3193 - val_mse: 0.3193 - val_mae: 0.4011\n",
      "Epoch 55/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3080 - mse: 0.3080 - mae: 0.3935 - val_loss: 0.3194 - val_mse: 0.3194 - val_mae: 0.4022\n",
      "Epoch 56/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3195 - mse: 0.3195 - mae: 0.4002 - val_loss: 0.3213 - val_mse: 0.3213 - val_mae: 0.3950\n",
      "Epoch 57/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3027 - mse: 0.3027 - mae: 0.3893 - val_loss: 0.3187 - val_mse: 0.3187 - val_mae: 0.3942\n",
      "Epoch 58/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3191 - mse: 0.3191 - mae: 0.3957 - val_loss: 0.3176 - val_mse: 0.3176 - val_mae: 0.3983\n",
      "Epoch 59/100\n",
      "362/362 [==============================] - 1s 1ms/step - loss: 0.3147 - mse: 0.3147 - mae: 0.3958 - val_loss: 0.3183 - val_mse: 0.3183 - val_mae: 0.4000\n",
      "Epoch 60/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3198 - mse: 0.3198 - mae: 0.3982 - val_loss: 0.3165 - val_mse: 0.3165 - val_mae: 0.3990\n",
      "Epoch 61/100\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.3245 - mse: 0.3245 - mae: 0.3999 - val_loss: 0.3152 - val_mse: 0.3152 - val_mae: 0.3942\n",
      "Epoch 62/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3020 - mse: 0.3020 - mae: 0.3924 - val_loss: 0.3175 - val_mse: 0.3175 - val_mae: 0.4009\n",
      "Epoch 63/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3161 - mse: 0.3161 - mae: 0.3970 - val_loss: 0.3176 - val_mse: 0.3176 - val_mae: 0.4011\n",
      "Epoch 64/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3043 - mse: 0.3043 - mae: 0.3913 - val_loss: 0.3174 - val_mse: 0.3174 - val_mae: 0.3959\n",
      "Epoch 65/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3215 - mse: 0.3215 - mae: 0.4009 - val_loss: 0.3131 - val_mse: 0.3131 - val_mae: 0.3953\n",
      "Epoch 66/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3081 - mse: 0.3081 - mae: 0.3956 - val_loss: 0.3133 - val_mse: 0.3133 - val_mae: 0.3981\n",
      "Epoch 67/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3072 - mse: 0.3072 - mae: 0.3926 - val_loss: 0.3115 - val_mse: 0.3115 - val_mae: 0.3939\n",
      "Epoch 68/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3070 - mse: 0.3070 - mae: 0.3935 - val_loss: 0.3098 - val_mse: 0.3098 - val_mae: 0.3914\n",
      "Epoch 69/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3056 - mse: 0.3056 - mae: 0.3929 - val_loss: 0.3100 - val_mse: 0.3100 - val_mae: 0.3953\n",
      "Epoch 70/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3002 - mse: 0.3002 - mae: 0.3880 - val_loss: 0.3103 - val_mse: 0.3103 - val_mae: 0.3915\n",
      "Epoch 71/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3051 - mse: 0.3051 - mae: 0.3918 - val_loss: 0.3120 - val_mse: 0.3120 - val_mae: 0.3913\n",
      "Epoch 72/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3048 - mse: 0.3048 - mae: 0.3897 - val_loss: 0.3127 - val_mse: 0.3127 - val_mae: 0.3882\n",
      "Epoch 73/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3047 - mse: 0.3047 - mae: 0.3893 - val_loss: 0.3129 - val_mse: 0.3129 - val_mae: 0.3947\n",
      "Epoch 74/100\n",
      "362/362 [==============================] - 0s 886us/step - loss: 0.3047 - mse: 0.3047 - mae: 0.3914 - val_loss: 0.3100 - val_mse: 0.3100 - val_mae: 0.3935\n",
      "Epoch 75/100\n",
      "362/362 [==============================] - 0s 879us/step - loss: 0.3025 - mse: 0.3025 - mae: 0.3865 - val_loss: 0.3136 - val_mse: 0.3136 - val_mae: 0.3997\n",
      "Epoch 76/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3137 - mse: 0.3137 - mae: 0.3910 - val_loss: 0.3077 - val_mse: 0.3077 - val_mae: 0.3885\n",
      "Epoch 77/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.2947 - mse: 0.2947 - mae: 0.3839 - val_loss: 0.3070 - val_mse: 0.3070 - val_mae: 0.3893\n",
      "Epoch 78/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3047 - mse: 0.3047 - mae: 0.3890 - val_loss: 0.3075 - val_mse: 0.3075 - val_mae: 0.3871\n",
      "Epoch 79/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3039 - mse: 0.3039 - mae: 0.3902 - val_loss: 0.3061 - val_mse: 0.3061 - val_mae: 0.3913\n",
      "Epoch 80/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.2993 - mse: 0.2993 - mae: 0.3867 - val_loss: 0.3066 - val_mse: 0.3066 - val_mae: 0.3934\n",
      "Epoch 81/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.2991 - mse: 0.2991 - mae: 0.3859 - val_loss: 0.3052 - val_mse: 0.3052 - val_mae: 0.3867\n",
      "Epoch 82/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3037 - mse: 0.3037 - mae: 0.3871 - val_loss: 0.3051 - val_mse: 0.3051 - val_mae: 0.3892\n",
      "Epoch 83/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.2863 - mse: 0.2863 - mae: 0.3788 - val_loss: 0.3053 - val_mse: 0.3053 - val_mae: 0.3837\n",
      "Epoch 84/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3024 - mse: 0.3024 - mae: 0.3878 - val_loss: 0.3024 - val_mse: 0.3024 - val_mae: 0.3841\n",
      "Epoch 85/100\n",
      "362/362 [==============================] - 0s 917us/step - loss: 0.2927 - mse: 0.2927 - mae: 0.3827 - val_loss: 0.3034 - val_mse: 0.3034 - val_mae: 0.3867\n",
      "Epoch 86/100\n",
      "362/362 [==============================] - 0s 975us/step - loss: 0.2977 - mse: 0.2977 - mae: 0.3845 - val_loss: 0.3003 - val_mse: 0.3003 - val_mae: 0.3819\n",
      "Epoch 87/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3029 - mse: 0.3029 - mae: 0.3860 - val_loss: 0.3002 - val_mse: 0.3002 - val_mae: 0.3882\n",
      "Epoch 88/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3027 - mse: 0.3027 - mae: 0.3904 - val_loss: 0.2995 - val_mse: 0.2995 - val_mae: 0.3829\n",
      "Epoch 89/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.2922 - mse: 0.2922 - mae: 0.3813 - val_loss: 0.2982 - val_mse: 0.2982 - val_mae: 0.3812\n",
      "Epoch 90/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.2872 - mse: 0.2872 - mae: 0.3764 - val_loss: 0.3019 - val_mse: 0.3019 - val_mae: 0.3869\n",
      "Epoch 91/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3057 - mse: 0.3057 - mae: 0.3885 - val_loss: 0.2974 - val_mse: 0.2974 - val_mae: 0.3810\n",
      "Epoch 92/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.2944 - mse: 0.2944 - mae: 0.3801 - val_loss: 0.2988 - val_mse: 0.2988 - val_mae: 0.3776\n",
      "Epoch 93/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3048 - mse: 0.3048 - mae: 0.3821 - val_loss: 0.2978 - val_mse: 0.2978 - val_mae: 0.3812\n",
      "Epoch 94/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.2966 - mse: 0.2966 - mae: 0.3796 - val_loss: 0.2973 - val_mse: 0.2973 - val_mae: 0.3825\n",
      "Epoch 95/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.3072 - mse: 0.3072 - mae: 0.3901 - val_loss: 0.2987 - val_mse: 0.2987 - val_mae: 0.3872\n",
      "Epoch 96/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.2958 - mse: 0.2958 - mae: 0.3794 - val_loss: 0.3019 - val_mse: 0.3019 - val_mae: 0.3906\n",
      "Epoch 97/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.2933 - mse: 0.2933 - mae: 0.3798 - val_loss: 0.2959 - val_mse: 0.2959 - val_mae: 0.3784\n",
      "Epoch 98/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.2939 - mse: 0.2939 - mae: 0.3792 - val_loss: 0.2987 - val_mse: 0.2987 - val_mae: 0.3875\n",
      "Epoch 99/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.2984 - mse: 0.2984 - mae: 0.3804 - val_loss: 0.2960 - val_mse: 0.2960 - val_mae: 0.3835\n",
      "Epoch 100/100\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.2969 - mse: 0.2969 - mae: 0.3819 - val_loss: 0.3000 - val_mse: 0.3000 - val_mae: 0.3899\n"
     ]
    }
   ],
   "source": [
    "# Se puede cambiar el tamaÃ±o del batch y las epocas \n",
    "history = model.fit(X_train,y_train,batch_size=32,epochs=100,validation_split=0.2,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mXI59B2-eAOA",
    "outputId": "158b362a-b866-4da8-8d7e-68ce2a32389f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.8818796],\n",
       "       [5.242335 ],\n",
       "       [1.2316169],\n",
       "       ...,\n",
       "       [1.2915999],\n",
       "       [0.8011545],\n",
       "       [2.5390742]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_eval)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DNN_Regressor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
